---
title: "Modelización de serie de tiempo de precios mayoristas de manzana de Uruguay."
author: "Emanuelle Marsella, Maximiliano Saldaña"
date: "Junio 2022"
output: 
  pdf_document:
    toc: no
    number_sections: true
header-includes:
  - \usepackage{float}
  - \usepackage[spanish]{babel} 
bibliography: bibliografia.bib
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  include = FALSE,
  warning = FALSE,
  out.width = '80%',
  fig.align="center")
```

```{r libs}
library(forecast)
library(dplyr)
library(ggplot2)
library(readr)
library(gridExtra)
library(tsoutliers)
library(urca)
```

```{r datos}
precios_manzana <- read_csv("precios_uam_long.csv")  %>% 
  filter(producto == "Manzana")

# Se pasa a formato ts
manzana <- ts(precios_manzana$precio_promedio, start = c(2013, 1), end = c(2022, 5) , frequency = 12)

```


# Resumen ejecutivo

# Análisis descriptivo

La serie a ser estudiada es la de precios promedio mensuales del kilo de manzana en la Unidad Agroalimentaria Metropolitana (ex Mercado Modelo). Los precios de los distintos rubros transados en este mercado mayorista de frutas y hortalizas son relevados por el Observatorio Granjero dos veces a la semana, los lunes y los jueves, mediante encuestas a los distintos vendedores informantes. Se relevan precios por distintas variedades, calidades y calibres. Empleando los distintos precios obtenidos los técnicos del Observatorio llegan a un precio de referencia por consenso.

Se cuentan con los datos desde enero de 2013 a mayo de 2022  y se considerará el promedio mensual de los precios, por lo que se cuentan con 113 observaciones. En lugar de emplear los datos bisemanales o el promedio semanal se opta por la frecuencia mensual debido a la dificultad de emplear el herramental de los modelos SARIMA para tales tipos de series, en particular para el tratamiento de la estacionalidad.


```{r plot_precios, fig.cap="Serie de precios mensuales del Kg de manzana en pesos Uruguayos.", include = TRUE}
autoplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Años)",  y = "Precio promedio ($UY por Kg)" )
```

En la figura \@ref(fig:plot_precios) se presenta el gráfico de la serie a ser trabajada. La impresión inicial que da es que la serie presenta cierto patrón estacional anual, donde los precios comienzan altos para luego descender hasta el segundo trimeste de los años y luego tienden a elevarse hasta el final de año. Esto se puede observar mejor en el gráfico de los precios coloreados por año y el gráfico de la evolución de los precios año a año por mes de la figura \@ref(fig:plot_precios_seas). El año 2020 presenta precios atípicamente altos y un comportamiento marcadamente distinto al de los otros años, no se observa la caída inicial de precios sino un aumento sostenido. Esto se puede deber al impacto económico que causó la pandemia de Coronavirus, que llegó a nuestro país en dicho año. Ya para 2021 y lo que va de 2022 parece haber una vuelta a patrones previos. Todo esto deberá ser tenido en cuenta a la hora de la especificación de un modelo del tipo ARIMA/SARIMA.

```{r plot_precios_seas, fig.cap="Serie de precios mensuales del Kg de manzana en pesos Uruguayos.", include = TRUE}
a <- ggseasonplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Mes)",  y = "Precio promedio ($UY por Kg)", title = NULL, color = "Año")

b <- ggsubseriesplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Mes)",  y = "Precio promedio ($UY por Kg)")


grid.arrange(a, b, nrow = 1)
```



```{r descomp, include=TRUE}
# Ver si incluir y en qué parte

descomp <- stl(manzana, s.window = 13)

autoplot(descomp) +
  theme_bw()
```
  
Para ahondar en el análisis descriptivo se realiza la descomposición de la serie en tendencia/ciclo, estacionalidad y componente irregular. En la figura \@ref(fig:descomp) se presentan las series de los componentes resultado de una descomposición mediante _STL_ (Seasonal Trend Descomposition using LOESS) por separado. 

<!-- Explicar STL -->

Se puede apreciar una marcada estacionalidad anual y en los últimos 6 años un ciclo corto que se repite cada dos años. La fuerza de la estacionalidad, definida como [@hyndman2018]:

$$F_s = max\left(0, 1-\frac{Var(R_t)}{Var(R_t+ S_t)}\right)$$
toma el valor 0.51 (entre más cercano a 1 más fuerte el componente). Esto refuerza la necesidad de considerar la estacionalidad a la hora de especificar un modelo. 

```{r}
# Fuerza de la estacionalidad
1- var(descomp$time.series[,3])/var(descomp$time.series[,3]+ descomp$time.series[,1])
```


# Metodología y resultados

```{r train_test}
# Se divide en muestra de training y de test
manzana_train <- window(manzana, end = c(2021, 5))
manzana_test <- window(manzana, start = c(2021, 6))

autoplot(manzana_train) +
  theme_bw()
```

```{r modelo1}
# MODELO IDENTIFICACIÓN MANUAL

# La transformación logarítmica no sería apropiada acá: la serie no aumenta en varianza con un aumento de media
# y el lambda de la transformación Box-Cox es != 0
BoxCox.lambda(manzana_train)

# Autocorrelación, serie original
acf1 <- ggAcf(manzana_train, type = "correlation", plot = FALSE, lag = 72) 
plot_acf1 <- autoplot(acf1) +
  labs(title = NULL) +
  theme_bw()

# Parecería que hay un decaimiento exponencial, pero en torno al lag 24 (2 años) vuelven a 
# haber autocorrelaciones significativas

# Autocorrelación parcial, serie original
pacf1 <- ggAcf(manzana_train, type = "partial", plot = FALSE,lag = 72)
plot_pacf1 <- autoplot(pacf1) +
  labs(title = NULL) +
  theme_bw()

grid.arrange(plot_acf1, plot_pacf1)

# En cualquier caso, estos gráficos no resultan definitivos para determinar si el proceso es trend stationary o difference stationary

# Test de raices unitarias
test_df_mod1 <- ur.df(manzana_train)
summary(test_df_mod1)

test_pp_mod1 <- ur.pp(manzana_train)
summary(test_pp_mod1)

# No rechazamos la hipótesis nula de que hay una raíz unitaria, usando los dos tests

# Probamos con una primera diferencia
manzana_train_diff <- diff(manzana_train)

autoplot(manzana_train_diff)

# El problema va a estar con las caídas abruptas a comienzos de los años
# En particular 2017 y 2021

# Autocorrelación
acf1_diff <- ggAcf(manzana_train_diff, type = "correlation", plot = FALSE, lag = 72) 
plot_acf1_diff <- autoplot(acf1_diff) +
  labs(title = NULL) +
  theme_bw()

# Autocorrelación parcial, serie diferenciada
pacf1_diff <- ggAcf(manzana_train_diff, type = "partial", plot = FALSE,lag = 72)
plot_pacf1_diff <- autoplot(pacf1_diff) +
  labs(title = NULL) +
  theme_bw()

grid.arrange(plot_acf1_diff, plot_pacf1_diff)

# Ahora queda el efecto del primer lag y del 24. En la PACF se aprecian autocorrelaciones positivas para los dos primeros lags

# Test de raices unitarias
test_df_mod1_diff <- ur.df(manzana_train_diff)
summary(test_df_mod1_diff)


test_pp_mod1_diff <- ur.pp(manzana_train_diff)
summary(test_pp_mod1_diff)
# Rechazamos la hipótesis de raíces unitarias


# Capaz se puede interpretar como un ARMA(2,1,1)(0,0,2)_12 
modelo1 <- Arima(manzana_train, order = c(2, 1, 1), seasonal = c(2, 0, 0))

summary(modelo1)
r1 <- residuals(modelo1)

# Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r1)

# Prueba de Ljung-Box
p_valores_box1 <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r1, lag = i, type = "Ljung-Box")$p.value)
  )

# No se rechaza la hipótesis nula de autocorrelación
p_valores_box1 %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

# Test de normalidad de Shapiro-Wilks y Jarque-Bera
shapiro.test(r1)
JarqueBera.test(r1)

# Se rechaza la hipótesis nula de normalidad,
# Los outliers son los sospechosos de ser culpables de esto
# Usamos el criterio estricto de Hyndman de que un atipico se aleja en 3*IQR del IQR 

outliers1 <- r1[(r1 < quantile(r1, 0.25) - 3*IQR(r1)) | (r1 > quantile(r1, 0.75) + 3*IQR(r1))]
    
outliers1_index <- which(r1 == outliers1[1] | r1 == outliers1[2])


# Probamos con insertar dummies, atípico AO o TC
# Se usan criterios de informacion para elegir el tipo

tipos_outliers <- list(
  tc_tc = outliers(c("TC", "TC"), outliers1_index),
  tc_ao = outliers(c("TC", "AO"), outliers1_index),
  ao_ao = outliers(c("AO", "AO"), outliers1_index),
  ao_tc = outliers(c("AO", "TC"), outliers1_index)
  )


outliers_effect <- outliers.effects(tipos_outliers[[1]], n = length(manzana_train))

modelo1_int <- Arima(manzana_train, order = c(2, 1, 1), seasonal = c(2, 0, 0), xreg = outliers_effect)

r1_int <- residuals(modelo1_int)

autoplot(r1_int)

# Tests de normalidad
shapiro.test(r1_int)
JarqueBera.test(r1_int)

# Sigue habiendo un atipico fuerte!

# Relajamos el criterio de outliers, porque sino no lo capta
outliers1_int <- r1_int[r1_int < quantile(r1_int, 0.25) - 2.5*IQR(r1_int) | r1_int > quantile(r1_int, 0.75) + 2.5*IQR(r1_int)]
    
outliers1_int_index <- which(r1_int == outliers1_int[1])

# Incluimos un AO
tipos_outliers_int <- outliers(c("TC", "AO", "TC"), c(49,50,99))

outliers_effect_int <- outliers.effects(tipos_outliers_int, n = length(manzana_train))


modelo1_int2 <- Arima(manzana_train, order = c(2, 1, 1), seasonal = c(2, 0, 0), xreg = outliers_effect_int)

r1_int2 <- residuals(modelo1_int2)

autoplot(r1_int2)

# Graficamos el efecto
outliers_effect_int_tbbl <- outliers_effect_int %>% 
  as_tibble() %>% 
  mutate(fecha = seq(as.Date("2013-01-01"), as.Date("2021-05-01"), by = "month"))

(plot_outliers_effects1 <- outliers_effect_int_tbbl %>% 
  ggplot() +
  geom_line(aes(x = fecha, y = TC49, color = "TC49")) +
  geom_line(aes(x = fecha, y = AO50, color = "AO50")) +
  geom_line(aes(x = fecha, y = TC99, color = "AO99")) +
  labs(color = "Outlier", y = "Efecto", x = "Tiempo (Año)") +
  theme_bw()) 

# Tests de normalidad
shapiro.test(r1_int2)
JarqueBera.test(r1_int2)

# No se rechaza la normalidad!

## Prueba de Ljung-Box (por las dudas)
p_valores_box1_int2 <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r1_int2, lag = i, type = "Ljung-Box")$p.value)
  )

# No se rechaza la hipótesis nula de autocorrelación al 5%
p_valores_box1_int2 %>% 
  ggplot(aes(lag, p_valores)) +
  geom_hline(yintercept = 0.05, color = "red") +
  geom_point()+
  theme_bw()

# Predicción 

npred <- length(manzana_test)
newxreg1 <- outliers.effects(tipos_outliers_int, n=length(manzana_train) + npred) 
  

outliers_pred1 <- newxreg1[(length(manzana)-npred+1):length(manzana),]

prediccion1 <- forecast(modelo1_int2, h = 12, xreg = outliers_pred1, level = c(20, 40, 60, 80, 95))

(plot_prediccion1 <- autoplot(prediccion1) + 
    autolayer(manzana_test) +
    labs(
      x = "Tiempo (Año)", 
      y = "Precio promedio ($UY X Kg)",
      title = "Predicción a 12 pasos de precios de manzana. ARIMA(2,1,1)(2,0,0)[12]. Intervenido.",
      color = ""
      ) +
    scale_color_manual(labels = c("Precios reales"), values = c("red")) +
    theme_bw())

# Acá tener en cuenta la problemática de incluir un outlier hacia el final del periodo de predicción

medidas_error1 <- accuracy(prediccion1, manzana_test)
```

```{r modelo2}
# MODELO ELEGIDO MEDIANTE CRITERIOS DE INFORMACIÓN

# Identificación y estimación ------------------------------------------
modelo2 <- auto.arima(manzana_train)

# Diagnóstico ------------------------------------------------------------
r2 <- residuals(modelo2)

## Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r2)

## Prueba de Ljung-Box
p_valores_box <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r2, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de autocorrelación
p_valores_box %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r2)
JarqueBera.test(r2)

# Vemos cuales son los atípicos

outliers2 <- r2[r2 < quantile(r2, 0.25) - 3*IQR(r2) | r2 > quantile(r2, 0.75) + 3*IQR(r2)]
outliers2_index <- which(r2 == outliers2[1] | r2 == outliers2[2])

tipos_outliers2 <- list(
  tc_tc = outliers(c("TC", "TC"), outliers2_index),
  tc_ao = outliers(c("TC", "AO"), outliers2_index),
  ao_ao = outliers(c("AO", "AO"), outliers2_index),
  ao_tc = outliers(c("AO", "TC"), outliers2_index)
  )

# Se aumenta el delta porque el outlier de 2017 tiene un efecto fuerte
outliers_effect2 <- outliers.effects(tipos_outliers[[1]], n = length(manzana_train), delta = 0.9)

modelo2_int <- Arima(manzana_train, order = c(0, 1, 2), seasonal = c(0, 0, 2), xreg = outliers_effect2)

r2_int <- residuals(modelo2_int)

autoplot(r2_int)

# Tests de normalidad
shapiro.test(r2_int)
JarqueBera.test(r2_int)

# Se rechaza la normalidad todavía, volvemos a intervenir

# Criterio de outliers de Hyndman
outliers2_int <- r2_int[r2_int < quantile(r2_int, 0.25) - 3*IQR(r2_int) | r2_int > quantile(r2_int, 0.75) + 3*IQR(r2_int)]
    
outliers2_int_index <- which(r2_int == outliers2_int[1] | r2_int == outliers2_int[2])

# Incluimos un AO
tipos_outliers2_int <- outliers(c("TC", "AO", "TC"), c(49,50,99))

outliers_effect2_int <- outliers.effects(tipos_outliers2_int, n = length(manzana_train))


modelo2_int2 <- Arima(manzana_train, order = c(0, 1, 2), seasonal = c(0, 0, 2), xreg = outliers_effect2_int)

r2_int2 <- residuals(modelo2_int2)

autoplot(r1_int2)

# Graficamos el efecto
outliers_effect_int_tbbl <- outliers_effect_int %>% 
  as_tibble() %>% 
  mutate(fecha = seq(as.Date("2013-01-01"), as.Date("2021-05-01"), by = "month"))

(plot_outliers_effects1 <- outliers_effect_int_tbbl %>% 
  ggplot() +
  geom_line(aes(x = fecha, y = TC49, color = "TC49")) +
  geom_line(aes(x = fecha, y = AO50, color = "AO50")) +
  geom_line(aes(x = fecha, y = TC99, color = "AO99")) +
  labs(color = "Outlier", y = "Efecto", x = "Tiempo (Año)") +
  theme_bw()) 

# Tests de normalidad
shapiro.test(r2_int2)
JarqueBera.test(r2_int2)

# No se rechaza la normalidad!

## Prueba de Ljung-Box (por las dudas)
p_valores_box2_int2 <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r2_int2, lag = i, type = "Ljung-Box")$p.value)
  )

# No se rechaza la hipótesis nula de autocorrelación al 5%
p_valores_box2_int2 %>% 
  ggplot(aes(lag, p_valores)) +
  geom_hline(yintercept = 0.05, color = "red") +
  geom_point()+
  theme_bw()

# Predicción 

newxreg2 <- outliers.effects(tipos_outliers2_int, n=length(manzana_train) + npred) 
  

outliers_pred2 <- newxreg2[(length(manzana)-npred+1):length(manzana),]

prediccion2 <- forecast(modelo2_int2, h = 12, xreg = outliers_pred2, level = c(20, 40, 60, 80, 95))

(plot_prediccion2 <- autoplot(prediccion2) + 
    autolayer(manzana_test) +
    labs(
      x = "Tiempo (Año)", 
      y = "Precio promedio ($UY X Kg)",
      title = "Predicción a 12 pasos de precios de manzana. ARIMA(0,1,2)(0,0,2)[12]. Intervenido.",
      color = ""
      ) +
    scale_color_manual(labels = c("Precios reales"), values = c("red")) +
    theme_bw())

# Acá tener en cuenta la problemática de incluir un outlier hacia el final del periodo de predicción
medidas_error2 <- accuracy(prediccion2, manzana_test)

```

```{r modelo3}
# MODELO CON INTERVENCIONES SELECCIONADAS POR TSO

# Identificación y estimación -----------------------------------------------------------
modelo_tso <- tso(manzana_train, types = c("TC", "AO"))


plot(modelo_tso)

# Diagnóstico ---------------------------------------------------------------------------

r_tso <- residuals(modelo_tso$fit)

## Gráfico de los residuos: los outliers siguen causando problemas con la normalidad
autoplot(r_tso)


ggAcf(r_tso)
ggAcf(r_tso, type = "partial")



## Prueba de Ljung-Box
p_valores_box_tso <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r_tso, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de no autocorrelación
p_valores_box_tso %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

# Test de normalidad de Shapiro-Wilks
shapiro.test(r_tso)
JarqueBera.test(r_tso)

# No se rechaza la hipótesis nula de normalidad


# Pasamos a la prediccion
npred <- length(manzana_test)

newxreg_tso <- outliers.effects(modelo_tso$outliers, n=length(manzana_train)+npred)

outliers_pred3 <- newxreg_tso[(length(manzana)-npred+1):length(manzana),]

prediccion_tso <- forecast(modelo_tso$fit, h = npred, xreg = outliers_pred3, level = c(20, 40, 60, 80, 95))


(plot_prediccion_tso <- autoplot(prediccion_tso) + 
    autolayer(manzana_test) +
    labs(
      x = "Tiempo (Año)", 
      y = "Precio promedio ($UY X Kg)",
      title = "Predicción a 12 pasos de precios de manzana. ARIMA(1,0,1)(1,1,0)[12]. Intervenido.",
      color = ""
      ) +
    scale_color_manual(labels = c("Precios reales"), values = c("red")) +
    theme_bw())

# Acá tener en cuenta la problemática de incluir un outlier hacia el final del periodo de predicción
medidas_error_tso <- accuracy(prediccion_tso, manzana_test)
```

```{r modelo4}
# MODELO CON INTERVENCIONES OBTENIDAS POR METODOS DEL PAQUETE TSOUTLIERS

## Se identifican los outliers y se sustituyen con una interpolación lineal
manzana_train_clean <- tsclean(manzana_train)

autoplot(manzana_train_clean)

# Identificación y estimación ----------------------------------------------------
modelo_clean <- auto.arima(manzana_train_clean)

# Diagnóstico ---------------------------------------------------------------------------
r_clean <- residuals(modelo_clean)

## Gráfico de los residuos: los outliers todavía presentes
autoplot(r_clean)

## Prueba de Ljung-Box
p_valores_box_clean <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r_clean, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de no autocorrelación
p_valores_box_clean %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r_clean)
JarqueBera.test(r_clean)


## Se rechaza la hipótesis nula de normalidad, usamos bootstrap para los intervalos.


prediccion_clean <- forecast(modelo_clean, bootstrap=TRUE, h=length(manzana_test), level = c(20, 40, 60, 80, 95))


(plot_prediccion_clean <- autoplot(prediccion_clean) +
    autolayer(manzana_test) +
    labs(
      x = "Tiempo (Año)", 
      y = "Precio promedio ($UY X Kg)",
      title = "Predicción a 12 pasos de precios de manzana. ARIMA(0,0,1)(2,0,0)[12]. Intervenido.",
      color = ""
      ) +
    scale_color_manual(labels = c("Precios reales"), values = c("red")) +
    theme_bw())


medidas_error_tso <- accuracy(prediccion_tso, manzana_test)

```

```{r modelo5}
# ETS
modelo_ets <- ets(manzana_train)

prediccion_ets <- forecast(modelo_ets, h = 12, level = c(20, 40, 60, 80, 95))

(plot_prediccion_ets <- prediccion_ets %>% 
  autoplot() +
  autolayer(manzana_test)+
    labs(
      x = "Tiempo (Año)", 
      y = "Precio promedio ($UY X Kg)",
      title = "Predicción a 12 pasos de precios de manzana. ETS(M, N, A)[12].",
      color = ""
      ) +
    scale_color_manual(labels = c("Precios reales"), values = c("red")) +
    theme_bw())

medidas_error_ets <- accuracy(prediccion_ets, manzana_test)

```

```{r modelo6}
# Modelo de espacio estado (estructural) - EXTRA SI DA EL TIEMPO
```


<!-- Desarrollo del informe de acá en adelante -->

## Muestra de entrenamiento y de prueba

Resulta de interés que el modelo ajustado a la serie sea de utilidad para la predicción. Para poder evaluar la calidad de las predicciones, una manera que busca replicar el proceso de obtención de nuevos datos es dividir la serie en una muestra de entrenamiento y una de prueba. La primera se emplea para ajustar el modelo, a partir del cual se realizarán las predicciones. Se dejan las últimas 12 observaciones para la muestra de prueba, que son los precios que van desde junio de 2021 a mayo de 2022. Debe tenerse en cuenta que el periodo del final de la muestra de entrenamiento y también la muestra de prueba están enmarcados en el contexto de gran incertidumbre que presenta la pandemia, por lo que deberá tenerse especial cuidado con el tratamiento de atípicos y las conclusiones que se tomen sobre las predicciones.

## Identificación

La primera fase para el modelado ARIMA de una serie de tiempo en el marco de la metodología de Box-Cox es la identificación del modelo, que consiste en determinar en un principio en detectar la estructura de autocorrelación, la cantidad de parámetros con la que contará la especificación, si la serie necesita diferenciación y si resultará necesaria alguna otra transformación. 

### Transformación logarítimica

La transformación logarítmica de una serie de tiempo puede tener como resultado una reducción del error de predicción en el caso de que estabilice la varianza [@lutkepohl2009]. Esto se cumple en particular cuando la varianza aumenta con la media de la serie, lo cual no es el caso de los precios de manzana, que si bien presentan una varianza que aumenta en el tiempo no parece haber una tendencia creciente clara. Por lo tanto, esta transformación no resultaría aconsejable de aplicar.  

Para confirmar esto, se considera la transformación de Box-Cox, donde siendo $y$ la variable transformada y $x$ la variable a transformar:

$$y_t = \begin{cases} \frac{x_t - 1}{\lambda} \,\,\, si \,\,\, \lambda \ne 0 \\ \ln x_t \,\,\, si \,\,\, \lambda = 0 \end{cases}$$

Donde el parámetro $\lambda$ se estima por máxima verosimilitud. En el caso de la serie planteada, dicho parámetro toma el valor -0.59, por lo que la transformación logarítmica no resulta adecuada.

### Autocorrelación y autocorrelación parcial

Como primer elemento a considerar en la identificación de un modelo ARIMA resultan útiles las funciones de autocorrelación y autocorrelación parcial. Al graficarlas en ellas se puede visualizar la estructura de dependencia temporal de la serie trabajada e indicios de la estacionariedad o ausencia de ella. La función de autocorrelación (ACF) se define como:

$$\rho(t, t+j) = \frac{Cov(Y_t, Y_{t+j})}{\sigma_t\sigma_{t+j}}  $$

Mientras que la función de autocorrelación parcial (PACF) es la autocorrelación entre  $Y_t$ y $Y_{t+j}$ una vez se quita el efecto de las correlaciones intermedias que hay entre ambas variables [@notas_series].

Estas funciones se deben estimar a partir de los datos, obteniéndose la autocorrelación muestral. En la figura \@ref(fig:acf1) se presentan los primeros 72 valores de ambas funciones para la serie original de precios de manzana, junto con el intervalo de confianza de la prueba de hipótesis $H_0) \rho_j = 0$ vs $H_0) \rho_j \ne 0$. En la ACF se puede distinguir que las primeras 5 autocorrelaciones resultan significativas y también las que están en torno al lag 24 y entre los lags 36 y 48. Esto puede ser un indicio de estacionalidad anual o bianual.

Por otro lado, en la PACF se aprecia que los valores para los primeros dos lags son significativamente distintos a 0. Esto puede ser un indicio de que hay una estructura autorregresiva en los datos.

### Dominio de las frecuencias

```{r acf1, fig.cap="Funciones de autocorrelación y autocorrelación parcial muestrales de la serie de precios de manzana.", include = TRUE}
grid.arrange(plot_acf1, plot_pacf1)
```

Desde la perspectiva del dominio de las frecuencias de la serie se considera esta última en su expresión trigonométrica, mediante una suma ponderada de funciones periódicas coseno y seno. El espectro poblacional puede resultar de utilizad para observar la estructura de variabilidad de la serie, dado que el área por debajo del mismo es la variabilidad asociada a las frecuencias consideradas.

En la figura \@ref(fig:espectro) se presenta la estimación no paramétrica del espectro poblacional de la serie de precios de manzana trabajada. En esta estimación se hace uso del periodograma muestral, que es la estimación del espectro poblacional a partir de las autocovarianzas muestrales y luego se realiza un promedio ponderado de sus valores mediante un _kernel_ a fines de suavizar el resultado, que en general resulta difícil de interpretar inicialmente. En este caso se pondera con el _kernel_ de Daniell modificado ponderando de a 3 valores del periodograma muestral 2 veces sucesivas. Se puede apreciar como las frecuencias menores, aquellas asociadas a periodos más largos (teniendo en cuenta que $p =2\pi/w$, siendo $p$ el periodo y $w$ la frecuencia) son aquellas que acumulan mayor variabilidad. Esto puede considerarse como otro indicio de una dependencia temporal estacional entre las observaciones de la muestra.

```{r espectro, includo = TRUE, fig.cap="Periodograma muestral, estimación no paramétrica. 3 spans aplicados 2 veces."}
# Estimación del espectro.
# Al agregar spans se está considerando la estimación no paramétrica.

spectrum(manzana_train,  spans = c(3, 3), main = "", xlab  = "Frecuencia", ylab = "Espectro")

# Que es la linea azul, un IC?
```


### Tests de raíces unitarias

Dado que las funciones de autocorrelación dieron indicios de que el proceso no es estacionario, resulta de interés poner a prueba si el proceso es $I(1)$, es decir, cuenta con una raíz unitaria. En dicho caso el proceso es no estacionario la cual implica que no puede ser modelado en el marco de los ARMA. 

Hay múltiples pruebas de hipótesis que han sido desarrolladas con el propósito de identificar raíces unitarias. Dos de ellos son el de Dickey-Fuller aumentado y el de Phillips-Perron. En el caso del primero se especifica el proceso proceso estocástico subyacente como:

$$Y_t = \rho Y_{t-1} + \varepsilon_t, \,\,\,\, \varepsilon_t \stackrel{\text{iid}}{\sim} N(0, \sigma^2)$$
Y se contrasta:

$$
H_0) \rho = 1 \\
H_1) \rho < 1 \\
$$

Empleando el estadístico $(\hat{\rho} - 1) / \sigma_{\hat{\rho}}$, que si $\rho$ es menor a 1 en valor absoluto se distribuye normal asintóticamente y si es igual a 1 debe usarse una distribución empírica tabulada por Fuller.

El test además toma en cuenta la posible autocorrelación de los errores incluyendo rezagos de la variable en la regresión auxiliar para mayor robustez.

Por otro lado la propuesta de prueba de raíz unitaria de Phillip-Perron se basa en la de Dickey y Fuller, pero además los compatibilizan con la presencia de heteroscedasticidad y/o autocorrelación de los errores.

Para la serie planteada, al observar los p-valores, ambos tests llevan a no rechazar la hipótesis de raíz unitaria al 95% de confianza. Esto lleva a concluir que una primera diferencia resulta necesaria para llevar la serie a la estacionariedad.

```{r acf2, include = TRUE, fig.cap= "Autocorrelograma y autocorrelograma parcial de la serie de primeras difernecias de precios de manzana."}
grid.arrange(plot_acf1_diff, plot_pacf1_diff)
```

Observando los nuevos autocorrelogramas se puede notar como el primer valor del ACF resulta significativamente distinto a 0 (lo cual puede ser indicio de un componente de medias móviles de orden 1) y lo mismo se da para los valores en torno al lag 24 y 48 (indicio de un componente estacional autorregresivo de orden 2). Esto último vuelve a indicar la presencia de una estructura de dependencia estacional. Por otro lado, en la PACF, se aprecia que solo los dos primeros valores son significativos, lo cual puede indicar cierta estructura autorregresiva, posiblemente de orden 2. A pesar de esto, hay que tener en cuenta que al tratar de identificar el orden de un proceso ARIMA mediante la FAC y PACF los elementos del procesos comienzan a mezclarse y no resulta tan claro la cantidad de parámetros a elegir. 

Teniendo en cuenta este acercamiento metodológico, inicialmente se plantea un modelo $ARIMA(2,1,1)(2,0,0)$, es decir, un modelo de la forma:

$$\Phi_2(L^{12})\phi_2(L)\Delta^1 Y_t = \theta_1(L)\varepsilon_t$$
Donde:

$$\Phi_2(L^{12}) = 1-\Phi_1L^{12}-\Phi_2 L^{24}$$

$$\phi_2(L) = 1-\phi_1 L-\phi_2 L^{2}$$

$$\Delta^1 = 1-L$$

$$\theta_1(L) = 1-\theta_1L$$

$$\epsilon_t \stackrel{\text{iid}}{\sim} N(0, \sigma^2) $$

### Selección mediante criterios de información

Una forma alternativa de elegir la especificación del modelo, esto es, la cantidad de parámetros y de diferencias, es mediante los criterios de información. Con estos criterios se busca elegir entre una selección de modelos aquel con una mayor verosimilitud, penalizando por la cantidad de parámetros que tenga. 

Uno de los más empleados y en particular el que se considera en la función _auto.arima()_ empleada para la estimación es el criterio de información de Akaike corregido (AICc). Su fórmula para un modelo es:

$$AICc = T\log{\hat{\sigma}^2_{MV}} + T \frac{1+k/T}{1-(k+2)/T}$$
Siendo $T$ el número de observaciones, $k$ el de parámetros y $\hat{\sigma}^2_{MV}$ el estimador máximo verosímil de la varianza de los errores. El modelo seleccionado es aquel con el menor valor del AICc, lo cuál a nivel algorítmico se hace empleando la selección _stepwise_ a partir de un conjunto inicial de modelos [@hyndman2018].

El modelo seleccionado mediante esta metodología resulta en un $ARIMA(0,1,2)(0,0,2)$. Se puede observar que no se considera componente autorregresivo, pero si un componente estacional de medias móviles y al igual que el anterior modelo, una diferencia (el algoritmo de _auto.arima()_ realiza multiples tests de raíz unitaria).

## Estimación

Luego de haber identificado la especificación del modelo, el paso que sigue es estimar sus parámetros, dado que no es posible conocer sus verdaderos valores al ser una construcción teórica. Para esto se recurre a la estimación por máxima verosimilitud, donde las estimaciones obtenidas son las que máximizan la probabilidad de que se haya obsevado la muestra con la que se cuenta. Es necesario asumir que los errores son gaussianos, un supuesto fuerte pero las estimaciones resultantes que emanen a partir de hacerlo serán razonables aunque no se cumpla [@hamilton_1994].

En particular, el método empleado es la estimacional máximo verosimil condicional, donde se supone que la primera observación de la serie es determinística y se maximiza la verosimilitud condicionada a esa observación, lo cual simplifica la operativa con las expresiones de las funciones y si el tamaño de muestra es razonablemente grande, la primera observación no tendrá gran efecto sobre la verosimilitud. 



## Diagnóstico

### Atípicos: La pandemia

Como se mencionó anteriormente, a simple vista es posible identificar que la pandemia de Coronavirus tuvo un impacto sobre los precios, así que esto deberá ser incluido en la modelización cuanto antes. Una manera de tener en cuenta este efecto atípico es considerar que hay un cambio transitorio (TC por sus siglas en inglés), un suceso que tiene un efecto que perdura en la serie pero no es permanente.

Posteriormente se deberá poner a prueba la presencia de otros atípicos.


## Predicción

Realizaremos predicción para los siguientes modelos, que son los que mejor cumplen los supuestos:

* **modelo_tso:** Modelo intervenido con el procedimiento automático de detección de outliers del paquete _tso_. Cumple tanto el supuesto de no autocorrelación de los residuos como el supuesto de normalidad.

* **modelo_clean:** Modelo intervenido con por métodos del paquete _tsoutliers_, que reemplaza los mismos a través de interpolación lineal. Cumple el supuesto de no autocorrelación de los residuos, pero no el supuesto de normalidad.

* **modelo_tbats:** Modelo TBATS (explicar más). Cumple el supuesto de no autocorrelación de los residuos, pero no el supuesto de normalidad (la única hipótesis nula que no se rechaza en este sentido es la de asimetría).



# Conclusiones