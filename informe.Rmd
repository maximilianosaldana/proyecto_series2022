---
title: "Modelización de serie de tiempo de precios mayoristas de manzana de Uruguay."
author: "Emanuelle Marsella, Maximiliano Saldaña"
date: "Junio 2022"
output: 
  pdf_document:
    toc: no
    number_sections: true
header-includes:
  - \usepackage{float}
  - \usepackage[spanish]{babel} 
bibliography: bibliografia.bib
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  include = FALSE,
  warning = FALSE,
  out.width = '80%',
  fig.align="center")
```

```{r libs}
library(forecast)
library(dplyr)
library(ggplot2)
library(readr)
library(gridExtra)
library(tsoutliers)
library(urca)
```

```{r datos}
precios_manzana <- read_csv("precios_uam_long.csv")  %>% 
  filter(producto == "Manzana")

# Se pasa a formato ts
manzana <- ts(precios_manzana$precio_promedio, start = c(2013, 1), end = c(2022, 5) , frequency = 12)

```



# Resumen ejecutivo

# Análisis descriptivo

La serie a ser estudiada es la de precios promedio mensuales del kilo de manzana en la Unidad Agroalimentaria Metropolitana (ex Mercado Modelo). Los precios de los distintos rubros transados en este mercado mayorista de frutas y hortalizas son relevados por el Observatorio Granjero dos veces a la semana, los lunes y los jueves, mediante encuestas a los distintos vendedores informantes. Se relevan precios por distintas variedades, calidades y calibres. Empleando los distintos precios obtenidos los técnicos del Observatorio llegan a un precio de referencia por consenso.

Se cuentan con los datos desde enero de 2013 a mayo de 2022  y se considerará el promedio mensual de los precios, por lo que se cuentan con 113 observaciones. En lugar de emplear los datos bisemanales o el promedio semanal se opta por la frecuencia mensual debido a la dificultad de emplear el herramental de los modelos SARIMA para tales tipos de series, en particular para el tratamiento de la estacionalidad.


```{r plot_precios, fig.cap="Serie de precios mensuales del Kg de manzana en pesos Uruguayos.", include = TRUE}
autoplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Años)",  y = "Precio promedio ($UY por Kg)" )
```

En la figura \@ref(fig:plot_precios) se presenta el gráfico de la serie a ser trabajada. La impresión inicial que da es que la serie presenta cierto patrón estacional anual, donde los precios comienzan altos para luego descender hasta el segundo trimeste de los años y luego tienden a elevarse hasta el final de año. Esto se puede observar mejor en el gráfico de los precios coloreados por año y el gráfico de la evolución de los precios año a año por mes de la figura \@ref(fig:plot_precios_seas). El año 2020 presenta precios atípicamente altos y un comportamiento marcadamente distinto al de los otros años, no se observa la caída inicial de precios sino un aumento sostenido. Esto se puede deber al impacto económico que causó la pandemia de Coronavirus, que llegó a nuestro país en dicho año. Ya para 2021 y lo que va de 2022 parece haber una vuelta a patrones previos. Todo esto deberá ser tenido en cuenta a la hora de la especificación de un modelo del tipo ARIMA/SARIMA.

```{r plot_precios_seas, fig.cap="Serie de precios mensuales del Kg de manzana en pesos Uruguayos.", include = TRUE}
a <- ggseasonplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Mes)",  y = "Precio promedio ($UY por Kg)", title = NULL, color = "Año")

b <- ggsubseriesplot(manzana) +
  theme_bw() +
  labs(x = "Tiempo (Mes)",  y = "Precio promedio ($UY por Kg)")


grid.arrange(a, b, nrow = 1)
```




```{r descomp}
# Ver si incluir y en qué parte

descomp <- stl(manzana, s.window = 13)

autoplot(descomp) +
  theme_bw()
```


# Metodología y resultados

```{r train_test}
# Se divide en muestra de training y de test
manzana_train <- window(manzana, end = c(2021, 5))
manzana_test <- window(manzana, start = c(2021, 6))

autoplot(manzana_train) +
  theme_bw()
```


```{r modelo1}
# MODELO IDENTIFICACIÓN MANUAL

## La transformación logarítmica no sería apropiada acá: la serie no aumenta en varianza con un aumento de media
## y el lambda de la transformación Box-Cox es != 0
BoxCox.lambda(manzana_train)

# Autocorrelación, serie original
acf1 <- ggAcf(manzana_train, type = "correlation", plot = FALSE, lag = 56) 
plot_acf1 <- autoplot(acf1) +
  labs(title = NULL) +
  theme_bw()

## Parecería que hay un decaimiento exponencial, pero en torno al lag 24 (2 años) vuelven a 
## haber autocorrelaciones significativas

# Autocorrelación parcial, serie original
pacf1 <- ggAcf(manzana_train, type = "partial", plot = FALSE,lag = 56)
plot_pacf1 <- autoplot(pacf1) +
  labs(title = NULL) +
  theme_bw()

grid.arrange(plot_acf1, plot_pacf1)

## En cualquier caso, estos gráficos no resultan definitivos para determinar si el proceso es trend stationary o difference stationary

# Test de raices unitarias
test_df_mod1 <- ur.df(manzana_train)
summary(test_df_mod1)

test_pp_mod1 <- ur.pp(manzana_train)
summary(test_pp_mod1)

## No rechazamos la hipótesis nula de que hay una raíz unitaria, usando los dos tests

## Probamos con una primera diferencia
manzana_train_diff <- diff(manzana_train)

autoplot(manzana_train_diff)

## El problema va a estar con las caídas abruptas a comienzos de los años
## En particular 2017 y 2021

# Autocorrelación
acf1_diff <- ggAcf(manzana_train_diff, type = "correlation", plot = FALSE, lag = 36) 
plot_acf1_diff <- autoplot(acf1_diff) +
  labs(title = NULL) +
  theme_bw()

# Autocorrelación parcial, serie diferenciada
pacf1_diff <- ggAcf(manzana_train_diff, type = "partial", plot = FALSE,lag = 36)
plot_pacf1_diff <- autoplot(pacf1_diff) +
  labs(title = NULL) +
  theme_bw()

grid.arrange(plot_acf1_diff, plot_pacf1_diff)

## Ahora queda el efecto del primer lag y del 24. En la PACF se aprecian autocorrelaciones positivas para los dos primeros lags

# Test de raices unitarias
test_df_mod1_diff <- ur.df(manzana_train_diff)
summary(test_df_mod1_diff)


test_pp_mod1_diff <- ur.pp(manzana_train_diff)
summary(test_pp_mod1_diff)
## Rechazamos la hipótesis de raíces unitarias


## Capaz se puede interpretar como un ARMA(2,1,1)(0,0,2)_12 
modelo1 <- Arima(manzana_train, order = c(2, 1, 1), seasonal = c(2, 0, 0))

summary(modelo1)
r1 <- residuals(modelo1)

## Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r1)

## Prueba de Ljung-Box
p_valores_box1 <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r1, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de autocorrelación
p_valores_box1 %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks y Jarque-Bera
shapiro.test(r1)
JarqueBera.test(r1)


## Se rechaza la hipótesis nula de normalidad


## El problema son los outliers de principio del año, capaz ts_clean?

manzana_train_diff_clean <- tsclean(manzana_train)

autoplot(manzana_train_diff_clean)

modelo1_clean <- Arima(manzana_train_diff, order = c(2, 0, 1), seasonal = c(0, 0, 2))

r1_clean <- residuals(modelo1_clean)

## Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r1_clean)

## Prueba de Ljung-Box
p_valores_box1_clean <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r1_clean, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de autocorrelación
p_valores_box1_clean %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r1_clean)
JarqueBera.test(r1_clean)

## Se rechaza la hipótesis nula de normalidad


# Probamos con insertar dummies






```





```{r}
# MODELO ELEGIDO MEDIANTE CRITERIOS DE INFORMACIÓN

# Identificación y estimación ----------------------------------------
modelo2 <- auto.arima(manzana_train)

# Diagnóstico -------------------------------------------------------
r2 <- residuals(modelo2)

## Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r2)

## Prueba de Ljung-Box
p_valores_box <- tibble(
  lag = 1:24, 
  p_valores = sapply(1:24, function(i) Box.test(r2, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de autocorrelación
p_valores_box %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r2)
JarqueBera.test(r2)
```


```{r}
# MODELO CON INTERVENCIONES SELECCIONADAS POR TSO

# Identificación y estimación -----------------------------------------------------------
modelo_tso <- tso(manzana_train, types = c("TC", "AO"))


plot(modelo_tso)

# Diagnóstico ---------------------------------------------------------------------------

r_tso <- residuals(modelo_tso$fit)

## Gráfico de los residuos: los outliers siguen causando problemas con la normalidad
autoplot(r_tso)


ggAcf(r_tso)
ggAcf(r_tso, type = "partial")



## Prueba de Ljung-Box
p_valores_box_tso <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r_tso, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de no autocorrelación
p_valores_box_tso %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r_tso)
JarqueBera.test(r_tso)

## No se rechaza la hipótesis nula de normalidad


```


```{r}
# MODELO CON INTERVENCIONES OBTENIDAS POR METODOS DEL PAQUETE TSOUTLIERS

## Se identifican los outliers y se sustituyen con una interpolación lineal
manzana_train_clean <- tsclean(manzana_train)

autoplot(manzana_train_clean)

# Identificación y estimación ----------------------------------------------------
modelo_clean <- auto.arima(manzana_train_clean)

# Diagnóstico ---------------------------------------------------------------------------

r_clean <- residuals(modelo_clean)

## Gráfico de los residuos: los outliers todavía presentes
autoplot(r_clean)

## Prueba de Ljung-Box
p_valores_box_clean <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r_clean, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de no autocorrelación
p_valores_box_clean %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks
shapiro.test(r_clean)
JarqueBera.test(r_clean)


## Se rechaza la hipótesis nula de normalidad

```


```{r}
# TBATS
modelo_tbats <- tbats(manzana_train)

r_tbats <- residuals(modelo_tbats)

## Gráfico de los residuos: los outliers causarán problemas con la normalidad
autoplot(r_tbats)

## Prueba de Ljung-Box
p_valores_box_tbats <- tibble(
  lag = 1:36, 
  p_valores = sapply(1:36, function(i) Box.test(r_tbats, lag = i, type = "Ljung-Box")$p.value)
  )

## No se rechaza la hipótesis nula de autocorrelación

p_valores_box_tbats %>% 
  ggplot() +
  geom_point(aes(lag, p_valores))+
  theme_bw()

## Test de normalidad de Shapiro-Wilks y Jarque-Bera
shapiro.test(r_tbats)
JarqueBera.test(r_tbats)

## Se rechaza la hipótesis nula de normalidad
```


```{r}
# ETS
```






<!-- Desarrollo del informe de acá en adelante -->

## Muestra de entrenamiento y de prueba

Resulta de interés que el modelo ajustado a la serie sea de utilidad para la predicción. Para poder evaluar la calidad de las predicciones, una manera que busca replicar el proceso de obtención de nuevos datos es dividir la serie en una muestra de entrenamiento y una de prueba. La primera se emplea para ajustar el modelo, a partir del cual se realizarán las predicciones. Se dejan las últimas 12 observaciones para la muestra de prueba, que son los precios que van desde junio de 2021 a mayo de 2022. Debe tenerse en cuenta que el periodo del final de la muestra de entrenamiento y también la muestra de prueba están enmarcados en el contexto de gran incertidumbre que presenta la pandemia, por lo que deberá tenerse especial cuidado con el tratamiento de atípicos y las conclusiones que se tomen sobre las predicciones.



## Identificación


### Autocorrelación y autocorrelación parcial


### Transformación logarítimica

La transformación logarítmica de una serie de tiempo puede tener como resultado una reducción del error de predicción en el caso de que estabilice la varianza [@lutkepohl2009]. Esto se cumple en particular cuando la varianza aumenta con la media de la serie, lo cual no es el caso de los precios de manzana, que si bien presentan una varianza que aumenta en el tiempo no parece haber una tendencia creciente clara. Por lo tanto, esta transformación no resultaría aconsejable de aplicar.  

Para confirmar esto, se considera la transformación de Box-Cox, donde siendo $y$ la variable transformada y $x$ la variable a transformar:

$$y_t = \begin{cases} \frac{x_t - 1}{\lambda} \,\,\, si \,\,\, \lambda \ne 0 \\ \ln x_t \,\,\, si \,\,\, \lambda = 0 \end{cases}$$

Donde el parámetro $\lambda$ se estima por máxima verosimilitud. En el caso de la serie planteada, dicho parámetro toma el valor -0.59, por lo que la transformación logarítmica no resulta adecuada.




### Atípicos: La pandemia

Como se mencionó anteriormente, a simple vista es posible identificar que la pandemia de Coronavirus tuvo un impacto sobre los precios, así que esto deberá ser incluido en la modelización cuanto antes. Una manera de tener en cuenta este efecto atípico es considerar que hay un cambio transitorio (TC por sus siglas en inglés), un suceso que tiene un efecto que perdura en la serie pero no es permanente.

Posteriormente se deberá poner a prueba la presencia de otros atípicos.




### Descomposición










## Estimación


## Diagnóstico

## Predicción

Realizaremos predicción para los siguientes modelos, que son los que mejor cumplen los supuestos:

* **modelo_tso:** Modelo intervenido con el procedimiento automático de detección de outliers del paquete _tso_. Cumple tanto el supuesto de no autocorrelación de los residuos como el supuesto de normalidad.

* **modelo_clean:** Modelo intervenido con por métodos del paquete _tsoutliers_, que reemplaza los mismos a través de interpolación lineal. Cumple el supuesto de no autocorrelación de los residuos, pero no el supuesto de normalidad.

* **modelo_tbats:** Modelo TBATS (explicar más). Cumple el supuesto de no autocorrelación de los residuos, pero no el supuesto de normalidad (la única hipótesis nula que no se rechaza en este sentido es la de asimetría).


```{r}
npred <- length(manzana_test)

newxreg <- outliers.effects(modelo_tso$outliers, n=length(manzana_train)+npred)
newxreg <- ts(newxreg[-seq_along(manzana_train),], start = c(2021, 6))

pred_tso <- predict(modelo_tso$fit, n.ahead=npred, newxreg=newxreg)

#Serie con valores originales de train + predicción
aux <- ts(c(manzana_train, pred_tso$pred), start = c(2013, 1), end = c(2022, 5) , frequency = 12) #Ver una forma menos manual de hacer esto

autoplot(aux) +
    autolayer(manzana_test) #Ver una mejor forma de graficar esto
```

```{r}
pred_clean <- forecast(modelo_clean, bootstrap=TRUE, h=length(manzana_test))
autoplot(pred_clean) +
    autolayer(manzana_test)
```

```{r}
pred_tbats <- forecast(modelo_tbats, bootstrap=TRUE, h=length(manzana_test))
autoplot(pred_tbats) +
    autolayer(manzana_test)
```

# Conclusiones